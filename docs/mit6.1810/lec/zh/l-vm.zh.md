---
title: 第15讲：虚拟内存与页表
---

6.1810 2024 第4讲：虚拟内存/页表

* **本讲计划:**
  - 地址空间
  - 分页硬件
  - xv6 虚拟内存代码

## 虚拟内存概述

* **今天的问题:**
  - [用户/内核图]
  - 假设 shell 有一个 bug：
    - 有时它会写入一个随机的内存地址
  - [物理内存, 0..2^64 : 应用程序和内核在同一内存中]
  - 我们如何防止它破坏内核？
    - 以及破坏其他进程？

* **我们想要隔离的地址空间**
  - 每个进程都有自己的内存
  - 它可以读写自己的内存
  - 它不能读写任何其他东西
  - **挑战:**
    - 如何将多个地址空间复用到一个物理内存上？
    - 同时保持隔离

* **xv6 使用 RISC-V 的分页硬件来实现地址空间**
  - 提问！这部分材料重要但复杂
  - 周四实验的主题（并在其他几个实验中出现）

* **页表为寻址提供了一个间接层**
  - CPU -> MMU -> RAM
  -   VA     PA
  - 软件只能对虚拟地址进行加载/存储，而不是物理地址
  - 内核告诉 MMU 如何将每个虚拟地址映射到物理地址
    - MMU 实质上有一个表，由 va 索引，产生 pa
    - 称为“页表”
    - va | pa
    - -------
    - x  |  y
  - 代码只能使用在表中有映射的地址

* **我们希望每个进程都有一个不同的地址空间**
  - 所以我们需要不止一个页表 —— 并且需要切换
  - MMU 有一个寄存器 (satp)，内核通过写入它来更改页表

* **页表存放在哪里？**
  - 在内存中
  - satp 保存当前页表的（物理）地址
  - MMU 从内存中加载页表条目
  - 内核可以通过在内存中写入来修改页表

* **一个页表有多大？**
  - 可能有 2^64 个不同的虚拟地址
  - 有一个包含 2^64 个条目的表是不切实际的！
  - 许多细节都是关于减小大小的

* **RISC-V 映射 4-KB 的“页”**
  - 所以页表只需要为每个页有一个条目
  - 4 KB = 12 位
  - RISC-V 有 64 位地址
  - 因此页表索引是 VA 的高 64-12 = 52 位
    - 除了高 52 位中的前 25 位未使用
      - 现在没有 RISC-V 有那么多内存
      - 未来可以增长
    - 所以，索引是 27 位。

* **图 3.1 -- 简化视图**
  - MMU 使用 VA 的索引位来查找页表条目 (PTE)
  - MMU 使用来自 PTE 的 PPN + VA 的偏移量来构造物理地址

* **PTE (页表条目) 中有什么？**
  - pte.pdf
  - [10 保留 | 44 PPN | 10 标志}
  - 每个 PTE 是 64 位，但只使用了 54 位
  - 44 位的 PPN (物理页号) 是 56 位物理地址的高位
  - PTE 的低 10 位是标志
    - 有效 (Valid), 可写 (Writeable), 等
  - 同样，物理地址的低 12 位是从虚拟地址复制的

* **页表只是一个 PTE 数组是否合理？**
  - 如图 3.1 所示
  - 由虚拟地址的 27 个索引位直接索引？
  - 页表会有多大？
  - 2^27 大约是 1.34 亿
  - 每个条目 64 位
  - 一个完整的页表需要 134*8 MB
    - 大约每个页表 1GB
    - 每个地址空间一个页表 -- 每个进程一个
  - 对于小程序会浪费大量内存！
    - 你可能只需要一小部分可能页面的映射
    - 所以其余的条目会消耗 RAM 但不需要

* **RISC-V 64 使用“三级页表”来节省空间**
  - 图 3.2
  - va 的高 9 位索引到一级页目录
  - 来自一级的 PTE 具有二级页目录的物理地址
    - 第二个 9 位索引二级目录
  - 第三个 9 位也是如此
    - 现在我们有了包含所需内存的页的 PTE
  - 它实际上是一棵树：[图]
    - 一次下降 9 位

* **为什么树形页表能节省空间？**

* **为什么是 9 位？**
  - 9 位决定了页目录的大小
  - 9 位 -> 512 个 PTE -> 64 位 / PTE -> 4096 字节，或一个页
  - 也就是说，9 位意味着一个目录适合一个页面

* **即使在硬件中发生，遍历树不是很昂贵吗？**
  - 是的，CPU 的 MMU 通常会缓存最近使用的翻译
  - 这个缓存被称为翻译后备缓冲区 (TLB)
  - 为了使 TLB 有效：页表支持超级页

* **PTE 中的标志**
  - V, R, W, X, U

* **如果 V 位未设置怎么办？或者存储时 W 位未设置？**
  - “页错误”
  - 强制转移到内核
    - xv6 源码中的 `trap.c`
  - xv6 内核只打印错误，杀死进程
    - `"usertrap(): unexpected scause ... pid=... sepc=... stval=..."`
  - 内核可以安装一个 PTE，恢复进程
    - 例如，从磁盘加载内存页后
    - 这里可能有很多技巧；我们会看到一些

## xv6 中的虚拟内存

* **内核页表**
  - 图 3.3
  - 左边是虚拟的
  - 右边是物理的

* **物理地址布局是什么？**
  - 通常由硬件定义 -- 板子
  - RAM 和内存映射的设备寄存器

* **对我们来说，qemu 模拟了板子，从而模拟了物理地址布局**
  - https://github.com/qemu/qemu/blob/master/hw/riscv/virt.c
  - `vi +60 virt.c`
  - MROM, UART, VIRTIO, DRAM
  - 与图 3.3 的右侧相同

* **图 3.3 的左侧由内核的页表定义**
  - 内核在启动时设置
  - 大多是“直接映射”
    - 允许内核使用物理地址作为虚拟地址
    - 非常方便！
  - 注意内核文本没有 W 位
  - 注意内核数据等没有 X 位
  - xv6 假设有 128 MB 的 RAM -- `PHYSTOP = 0x88000000`
    - 应该动态地找到 RAM 大小！
  - 在最顶端：trampoline, 内核堆栈
    - 注意高地址的页有*两个*虚拟映射！
  - 内核在切换页表时在 trampoline 中执行
    - 创建用户页表，在相同的 va 处有相同的 trampoline

* **我们可以在没有分页的情况下运行内核吗？关闭 MMU？**
  - 通常可以这样做（取决于 CPU 设计）
  - 为什么要对内核进行分页？
    - 将 RAM 放在预期位置
    - 双重映射
    - 禁止某些访问以捕获错误

* **每个进程都有自己的地址空间**
  - 内核为每个进程创建一个单独的页表
  - 图 3.4
  - 内核在切换进程时切换页表（即设置 satp）
  - 不同的进程有相似的虚拟地址布局
    - 但页表映射到 RAM 中不同的物理地址

* **为什么是这种用户地址空间安排？**
  - 用户虚拟地址从零开始
    - 可预测，编译器更容易生成代码
  - 连续地址 -- 对例如大数组有好处
    - 但不必有连续的物理内存 -- 没有碎片问题
  - 有很大的地址范围可以增长
  - 内核和用户都映射 trampoline 页
    - 简化了从用户到内核以及返回的转换
    - 但 U 位未设置
  - 内核如何使用用户虚拟地址，例如传递给 `read()` 的地址？
    - 内核软件必须翻译成内核虚拟地址
    - 参考该进程的页表

## 代码走读

* **内核地址空间的设置**
  - 内核启动时未启用分页，所以地址是物理的
    - 内核被编译/链接到从 0x80000000 开始，那里是 RAM
  - 内核必须首先创建自己的页表
  - `vm.c` 中的 `kvmmake()`
  - 构建图 3.3
  - UART0 在 pa=0x10000000，希望在 va=0x10000000 进行直接映射
  - `kvmmap()` 将 PTE 添加到正在构建的页表中
    - 我们还没有使用它，它只是内存中的数据

* **让我们 `vmprint()` 生成的页表（你将编写 `vmprint()`）**
  - [画树，注意第一个 PTE 的 PPN 指示了二级位置等]
  - 页目录页来自 `kalloc()`
    - 由于 `kinit()` 的工作方式，是顺序的
  - `0..128..0` 是否对应于 `va=0x10000000`？
    - 哪个 VA 会使用那个页表条目？
    - `[ L2=0 | L1=128 | L0=0 | offset=0 ]`
    - `(gdb) print/x 128 << (9+12)`
    - `$3 = 0x10000000`
    - 所以 va 是 `128 << (12+9) = 0x10000000`，如预期

* **UART 的最后一级 PTE 是否引用了预期的物理地址？**
  - `(gdb) print/x (0x10000000 >> 12) << 10`
  - `$2 = 0x4000000`
  - PTE 的低位中的 7 是什么？

* **映射了两个页呢？**
  - 将 `vmprint` 移动到 VIRTIO0 被映射之后
  - [添加到树]

* **完整的内核页表？**
  - 太大了，无法用这种方式打印
  - 你可以向 qemu 请求 satp 中的页表
  - `^a c`
  - `info mem`
  - 注意 UART, RAM, trampoline 在最顶端
  - `^a c` (恢复)

* **`kvmmap()` 调用 `vm.c` 中的 `mappages()`**
  - 参数是根 PD, va, size, pa, perm
  - 添加从一系列 va 到相应 pa 的映射
  - 对于范围内的每个页
    - 调用 `walk` 找到 PTE 的地址
      - 需要 PTE 的地址（不仅仅是内容），因为我们要修改它
      - 如果需要，`walk` 会创建页目录页
    - 将所需的 pa 放入 PTE
    - 用 `PTE_V` 标记 PTE 为有效

* **`vm.c` 中的 `walk()`**
  - `walk()` 模仿分页硬件如何找到地址的 PTE
  - 通过三个目录页下降三级
  - `PX(level, va)` 提取 Level 级别的 9 位
  - `pagetable` 的 C 类型是一个 512 个条目的 64 位整数数组 (PTEs)
  - 所以 `&pagetable[PX(level, va)]` 是我们想要的 PTE 的地址
  - 除了最后一级：
    - 如果 `PTE_V`
      - 相关的页表页已经存在
      - `PTE2PA` 从 PTE 中提取 PPN 作为 PA
      - 内核可以使用它（作为 va）来读取下一级
    - 如果不是 `PTE_V`
      - `kalloc()` 一个新的页表页
      - 用 PPN 填充 pte (使用 `PA2PTE`)
      - 并将其标记为 `PTE_V`
  - 现在我们想要的 PTE 在页表页中

* **`kvminithart()`**
  - 将页表的根地址加载到 satp
  - **问：** 地址是虚拟地址还是物理地址？

* **TLB 管理**
  - CPU 缓存分页翻译以提高速度
  - xv6 在用户/内核转换期间刷新整个 TLB
    - 为什么？
  - RISC-V 允许更复杂的计划
    - `PTE_G`: 全局 TLB 位
      - 哪个页可以使用这个？
    - ASID 号码
      - TLB 条目用 ASID 标记，因此内核可以有选择地刷新
      - SATP 接受一个 ASID 号码
      - `sfence.vma` 也接受一个 ASID 号码
    - 超级页
      - 2MB 和 1GB
